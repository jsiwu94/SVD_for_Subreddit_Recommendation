{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit Recommendation System using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://assets.ifttt.com/images/channels/1352860597/icons/on_color_large.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import csv\n",
    "from pandas import DataFrame,Series,read_csv\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from sparsesvd import sparsesvd        #used for matrix factorization\n",
    "from scipy.sparse import csc_matrix    #used for sparse matrix\n",
    "from scipy.sparse.linalg import *      #used for matrix multiplication\n",
    "from scipy.linalg import sqrtm\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = read_csv('/Users/jenniferwu/Documents/SVD_for_Subreddit_Recommendation/reddit_praw.csv')\n",
    "reddit_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kabanossi</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>1.482748e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kabanossi</td>\n",
       "      <td>GetMotivated</td>\n",
       "      <td>1.482748e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kabanossi</td>\n",
       "      <td>vmware</td>\n",
       "      <td>1.482748e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kabanossi</td>\n",
       "      <td>carporn</td>\n",
       "      <td>1.482748e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kabanossi</td>\n",
       "      <td>DIY</td>\n",
       "      <td>1.482747e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    username         subreddit           utc\n",
       "0  kabanossi  photoshopbattles  1.482748e+09\n",
       "1  kabanossi      GetMotivated  1.482748e+09\n",
       "2  kabanossi            vmware  1.482748e+09\n",
       "3  kabanossi           carporn  1.482748e+09\n",
       "4  kabanossi               DIY  1.482747e+09"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique reddittor: 15000\n",
      "unique subreddit: 29281\n",
      "total data entry: (9391244, 3)\n"
     ]
    }
   ],
   "source": [
    "user = reddit_df.username.unique()\n",
    "subreddit = reddit_df.subreddit.unique()\n",
    "print('unique reddittor:',len(user)+1)\n",
    "print('unique subreddit:',len(subreddit)+1)\n",
    "print('total data entry:',reddit_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there null values from our API dataset?  \n",
      "username     False\n",
      "subreddit    False\n",
      "utc          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Are there null values from our API dataset?  \\n\" + str(reddit_df.isnull().any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our SVD Model - with Test & Train by Sampling 500 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_username = list(reddit_df.username.unique())[300:800]\n",
    "sample_df = reddit_df[reddit_df.username.isin(sample_username)]\n",
    "\n",
    "users = list(sample_df.username.unique())\n",
    "subreddits = list(sample_df.subreddit.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 134 subreddits contribute a total of 64.9 % to the total subreddits in the dataset\n"
     ]
    }
   ],
   "source": [
    "subs_freq = sample_df.groupby(['subreddit']\n",
    "                                      , as_index=False).agg({'username': 'count'}).sort_values(by=['username']\n",
    "                                      , ascending=False).reset_index(drop=True).rename(columns={'username':'username_count'})\n",
    "subs_freq['cummulative_pct'] = subs_freq.username_count.cumsum()/subs_freq.username_count.sum()*100\n",
    "\n",
    "latent_fac = subs_freq.subreddit[subs_freq.cummulative_pct <= 65].count()\n",
    "contribution_pcts = round(subs_freq.cummulative_pct[len(subs_freq.subreddit[subs_freq.cummulative_pct <= 65])-1],1)\n",
    "\n",
    "print(\"Top\", latent_fac ,\"subreddits contribute a total of\"\n",
    "      , contribution_pcts,\"%\", \"to the total subreddits in the dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_freq</th>\n",
       "      <th>most_recent_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-SA-HatfulOfHollow</td>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "      <td>1.482761e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-SA-HatfulOfHollow</td>\n",
       "      <td>reddevils</td>\n",
       "      <td>1</td>\n",
       "      <td>1.482742e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-SA-HatfulOfHollow</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1</td>\n",
       "      <td>1.482771e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-SA-HatfulOfHollow</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>11</td>\n",
       "      <td>1.476293e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>Android</td>\n",
       "      <td>3</td>\n",
       "      <td>1.475605e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>AskAnthropology</td>\n",
       "      <td>2</td>\n",
       "      <td>1.480134e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482744e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>6</td>\n",
       "      <td>1.482560e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>CrazyIdeas</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480079e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-_-_-_-otalp-_-_-_-</td>\n",
       "      <td>DC_Cinematic</td>\n",
       "      <td>2</td>\n",
       "      <td>1.476638e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              username           subreddit  submission_freq  \\\n",
       "0   -SA-HatfulOfHollow                news                1   \n",
       "1   -SA-HatfulOfHollow           reddevils                1   \n",
       "2   -SA-HatfulOfHollow              soccer                1   \n",
       "3   -SA-HatfulOfHollow           worldnews               11   \n",
       "4  -_-_-_-otalp-_-_-_-             Android                3   \n",
       "5  -_-_-_-otalp-_-_-_-     AskAnthropology                2   \n",
       "6  -_-_-_-otalp-_-_-_-           AskReddit                2   \n",
       "7  -_-_-_-otalp-_-_-_-  BlackPeopleTwitter                6   \n",
       "8  -_-_-_-otalp-_-_-_-          CrazyIdeas                1   \n",
       "9  -_-_-_-otalp-_-_-_-        DC_Cinematic                2   \n",
       "\n",
       "   most_recent_timestamp  \n",
       "0           1.482761e+09  \n",
       "1           1.482742e+09  \n",
       "2           1.482771e+09  \n",
       "3           1.476293e+09  \n",
       "4           1.475605e+09  \n",
       "5           1.480134e+09  \n",
       "6           1.482744e+09  \n",
       "7           1.482560e+09  \n",
       "8           1.480079e+09  \n",
       "9           1.476638e+09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =sample_df.groupby(['username','subreddit']).agg({'subreddit':'count',\n",
    "                                                                 'utc':'max'}).\\\n",
    "              rename(columns={'subreddit':'submission_freq','utc':'most_recent_timestamp'}).reset_index()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_sum = data.groupby(['username'], as_index=False).agg({'submission_freq':'sum'})\n",
    "temp = pd.merge(left = data, right = user_sum, how='left', left_on='username',right_on='username').\\\n",
    "                rename(columns={'submission_freq_y':'user_sum',\n",
    "                               'submission_freq_x':'submission_freq'})\n",
    "data['user_implicit_rating'] = temp.submission_freq/temp.user_sum\n",
    "data.drop(columns=['submission_freq'], inplace=True)\n",
    "data = pd.concat([data.iloc[:,:2],data.iloc[:,-1:],data['most_recent_timestamp']], axis=1)\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32018, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Train and Test Dataset based on Timestamp (utc)\n",
    "\n",
    "- Calculating implicit rating using number of submissions per subreddit.\n",
    "- Ideally need data for upvotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "users = data['username'].unique() #list of all users\n",
    "subs = data['subreddit'].unique() #list of all movies\n",
    "\n",
    "test = pd.DataFrame(columns=data.columns)\n",
    "train = pd.DataFrame(columns=data.columns)\n",
    "test_ratio = 0.2 #fraction of data to be used as test set.\n",
    "temp1 = data[data.username.isin(users)]\n",
    "for u in users:\n",
    "    n = len(temp1)\n",
    "    test_size = int(test_ratio*n)\n",
    "\n",
    "temp1 = temp1.sort_values('most_recent_timestamp').reset_index()\n",
    "temp1.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "dummy_test = temp1.ix[n-1-test_size :]\n",
    "dummy_train = temp1.ix[: n-2-test_size]\n",
    "    \n",
    "test = pd.concat([test, dummy_test])\n",
    "train = pd.concat([train, dummy_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data for User \"-_-_-_-otalp-_-_-_-\"        :\n",
      "                  username             subreddit  user_implicit_rating\n",
      "11220  -_-_-_-otalp-_-_-_-             worldnews              0.001017\n",
      "11222  -_-_-_-otalp-_-_-_-            OCOCTATIAT              0.001017\n",
      "11365  -_-_-_-otalp-_-_-_-           nottheonion              0.001017\n",
      "11405  -_-_-_-otalp-_-_-_-     millionairemakers              0.001017\n",
      "11600  -_-_-_-otalp-_-_-_-          changemyview              0.001017\n",
      "11650  -_-_-_-otalp-_-_-_-                  news              0.001017\n",
      "12684  -_-_-_-otalp-_-_-_-               Android              0.003052\n",
      "13535  -_-_-_-otalp-_-_-_-               chomsky              0.002035\n",
      "13634  -_-_-_-otalp-_-_-_-          DC_Cinematic              0.002035\n",
      "14440  -_-_-_-otalp-_-_-_-        TheoryOfReddit              0.002035\n",
      "14453  -_-_-_-otalp-_-_-_-         UpliftingNews              0.001017\n",
      "14629  -_-_-_-otalp-_-_-_-          the_meltdown              0.001017\n",
      "15198  -_-_-_-otalp-_-_-_-               pokemon              0.001017\n",
      "15316  -_-_-_-otalp-_-_-_-             australia              0.009156\n",
      "15339  -_-_-_-otalp-_-_-_-  Political_Revolution              0.005086\n",
      "15684  -_-_-_-otalp-_-_-_-                 funny              0.004069\n",
      "15685  -_-_-_-otalp-_-_-_-                 Jokes              0.001017\n",
      "16391  -_-_-_-otalp-_-_-_-                  gifs              0.001017\n",
      "16633  -_-_-_-otalp-_-_-_-              counting              0.001017\n",
      "17434  -_-_-_-otalp-_-_-_-                iphone              0.004069\n",
      "19305  -_-_-_-otalp-_-_-_-            CrazyIdeas              0.001017\n",
      "19452  -_-_-_-otalp-_-_-_-            badhistory              0.001017\n",
      "19464  -_-_-_-otalp-_-_-_-       AskAnthropology              0.002035\n",
      "21413  -_-_-_-otalp-_-_-_-                 otalp              0.001017\n",
      "23433  -_-_-_-otalp-_-_-_-       depressedrobots              0.001017\n",
      "23808  -_-_-_-otalp-_-_-_-       EnoughTrumpSpam              0.053917\n",
      " \n",
      "Test Data for User \"-_-_-_-otalp-_-_-_-\"        :\n",
      "                  username           subreddit  user_implicit_rating\n",
      "25662  -_-_-_-otalp-_-_-_-              me_irl              0.001017\n",
      "25708  -_-_-_-otalp-_-_-_-           socialism              0.002035\n",
      "26122  -_-_-_-otalp-_-_-_-           spacemacs              0.001017\n",
      "26438  -_-_-_-otalp-_-_-_-           radiohead              0.008138\n",
      "26816  -_-_-_-otalp-_-_-_-               meirl              0.001017\n",
      "27038  -_-_-_-otalp-_-_-_-               Music              0.005086\n",
      "27570  -_-_-_-otalp-_-_-_-          indieheads              0.001017\n",
      "28582  -_-_-_-otalp-_-_-_-      Showerthoughts              0.003052\n",
      "28839  -_-_-_-otalp-_-_-_-              movies              0.014242\n",
      "29181  -_-_-_-otalp-_-_-_-            politics              0.060020\n",
      "29186  -_-_-_-otalp-_-_-_-  BlackPeopleTwitter              0.006104\n",
      "29432  -_-_-_-otalp-_-_-_-           dagandred              0.010173\n",
      "29917  -_-_-_-otalp-_-_-_-         LiverpoolFC              0.379451\n",
      "29974  -_-_-_-otalp-_-_-_-            Fuck2016              0.018311\n",
      "30335  -_-_-_-otalp-_-_-_-            bidenbro              0.001017\n",
      "30379  -_-_-_-otalp-_-_-_-               apple              0.005086\n",
      "30955  -_-_-_-otalp-_-_-_-             atheism              0.001017\n",
      "30956  -_-_-_-otalp-_-_-_-           AskReddit              0.002035\n",
      "30969  -_-_-_-otalp-_-_-_-          botsrights              0.027467\n",
      "31486  -_-_-_-otalp-_-_-_-              soccer              0.348932\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Train Data for User \"-_-_-_-otalp-_-_-_-\"        :\"\"\")\n",
    "print(train[train.username == '-_-_-_-otalp-_-_-_-'].iloc[:,:3])\n",
    "print(\" \")\n",
    "print(\"\"\"Test Data for User \"-_-_-_-otalp-_-_-_-\"        :\"\"\")\n",
    "print(test[test.username == '-_-_-_-otalp-_-_-_-'].iloc[:,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the Dataframe into Utility Matrix for SVD Computation Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "userList = data.ix[:,0].tolist()\n",
    "itemList = data.ix[:,1].tolist()\n",
    "valueList = data.ix[:,2].tolist()\n",
    "users = list(set(data.ix[:,0]))\n",
    "items = list(set(data.ix[:,1]))\n",
    "users_index = {users[i]: i for i in range(len(users))}\n",
    "pd_dict = {item: [np.nan for i in range(len(users))] for item in items}\n",
    "for i in range(0,len(data)):\n",
    "    item = itemList[i]\n",
    "    user = userList[i]\n",
    "    value = valueList[i]\n",
    "    pd_dict[item][users_index[user]] = value\n",
    "X = pd.DataFrame(pd_dict)\n",
    "X.index = users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-_-_-_-otalp-_-_-_-    0.348932\n",
       "Name: soccer, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.index == '-_-_-_-otalp-_-_-_-']['soccer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(train, k):\n",
    "    utilMat = np.array(train)\n",
    "    # the nan or unavailable entries are masked\n",
    "    mask = np.isnan(utilMat)\n",
    "    masked_arr = np.ma.masked_array(utilMat, mask)\n",
    "    item_means = np.mean(masked_arr, axis=0)\n",
    "    # nan entries will replaced by the average rating for each item\n",
    "    utilMat = masked_arr.filled(item_means)\n",
    "    x = np.tile(item_means, (utilMat.shape[0],1))\n",
    "    # we remove the per item average from all entries.\n",
    "    # the above mentioned nan entries will be essentially zero now\n",
    "    utilMat = utilMat - x\n",
    "    # The magic happens here. U and V are user and item features\n",
    "    U, s, V=np.linalg.svd(utilMat, full_matrices=False)\n",
    "    s=np.diag(s)\n",
    "    # we take only the k most significant features\n",
    "    s=s[0:k,0:k]\n",
    "    U=U[:,0:k]\n",
    "    V=V[0:k,:]\n",
    "    s_root=sqrtm(s)\n",
    "    Usk=np.dot(U,s_root)\n",
    "    skV=np.dot(s_root,V)\n",
    "    UsV = np.dot(Usk, skV)\n",
    "    UsV = UsV + x\n",
    "    print(\"svd done\")\n",
    "    return UsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svd done\n",
      "0.0001907806366327251\n",
      "0.005219784277697061\n"
     ]
    }
   ],
   "source": [
    "def mse(true, pred):\n",
    "    # this will be used towards the end\n",
    "    x = true - pred\n",
    "    return sum([xi*xi for xi in x])/len(x)\n",
    "\n",
    "def mae(true, pred):\n",
    "    # this will be used towards the end\n",
    "    x = abs(true - pred)\n",
    "    return sum([xi for xi in x])/len(x)\n",
    "\n",
    "\n",
    "# to test the performance over a different number of features\n",
    "no_of_features = [134]\n",
    "\n",
    "svdout = svd(X, k=134)\n",
    "pred = [] #to store the predicted ratings\n",
    "    \n",
    "for _,row in test.iterrows():\n",
    "        user = row['username']\n",
    "        item = row['subreddit']\n",
    "        u_index = users_index[user]\n",
    "        if item in items_index:\n",
    "            i_index = items_index[item]\n",
    "            pred_rating = svdout[u_index, i_index]\n",
    "        else:\n",
    "            pred_rating = np.mean(svdout[u_index, :])\n",
    "        pred.append(pred_rating)\n",
    "print(mse(test['user_implicit_rating'], pred))\n",
    "print(mae(test['user_implicit_rating'], pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset for our SVD Recommendation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>username_count</th>\n",
       "      <th>cummulative_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>683932</td>\n",
       "      <td>7.282656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>260215</td>\n",
       "      <td>10.053482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>146480</td>\n",
       "      <td>11.613232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfl</td>\n",
       "      <td>122088</td>\n",
       "      <td>12.913252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>109187</td>\n",
       "      <td>14.075899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  username_count  cummulative_pct\n",
       "0   AskReddit          683932         7.282656\n",
       "1    politics          260215        10.053482\n",
       "2  The_Donald          146480        11.613232\n",
       "3         nfl          122088        12.913252\n",
       "4   worldnews          109187        14.075899"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_subreddit = reddit_df.groupby(['subreddit']\n",
    "                                      , as_index=False).agg({'username': 'count'}).sort_values(by=['username']\n",
    "                                      , ascending=False).reset_index(drop=True).rename(columns={'username':'username_count'})\n",
    "top_subreddit['cummulative_pct'] = top_subreddit.username_count.cumsum()/top_subreddit.username_count.sum()*100\n",
    "top_subreddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Testosterone Testosterone Testosterone Testost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--Sko--</td>\n",
       "      <td>DestinyTheGame DestinyTheGame DestinyTheGame D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--UNKN0WN--</td>\n",
       "      <td>AceAttorney AceAttorney AceAttorney AceAttorne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--harley--quinn--</td>\n",
       "      <td>LGBTeens Patriots asktransgender Patriots Patr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-A-p-r-i-l-</td>\n",
       "      <td>tdi tdi tdi AskReddit tdi tdi tdi tdi tdi tdi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                                          subreddit\n",
       "0        --ANUSTART-  Testosterone Testosterone Testosterone Testost...\n",
       "1            --Sko--  DestinyTheGame DestinyTheGame DestinyTheGame D...\n",
       "2        --UNKN0WN--  AceAttorney AceAttorney AceAttorney AceAttorne...\n",
       "3  --harley--quinn--  LGBTeens Patriots asktransgender Patriots Patr...\n",
       "4        -A-p-r-i-l-  tdi tdi tdi AskReddit tdi tdi tdi tdi tdi tdi ..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = reddit_df.username.unique()\n",
    "subreddit = reddit_df.subreddit.unique()\n",
    "doc_df = reddit_df.groupby('username')['subreddit'].apply(lambda x: \"%s\" % ' '.join(x)).reset_index()\n",
    "doc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Testosterone, Testosterone, Testosterone, Tes...\n",
       "1    [DestinyTheGame, DestinyTheGame, DestinyTheGam...\n",
       "2    [AceAttorney, AceAttorney, AceAttorney, AceAtt...\n",
       "3    [LGBTeens, Patriots, asktransgender, Patriots,...\n",
       "4    [tdi, tdi, tdi, AskReddit, tdi, tdi, tdi, tdi,...\n",
       "Name: subreddit, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "document = doc_df.iloc[:, 1]\n",
    "document = document.apply(lambda row: tokenizer.tokenize(row))\n",
    "document.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating User-Subreddit Matrix\n",
    "Using CSC Matrix to Handle highly sparse matrix. To view normally, use : user_subreddit_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 29280)\n"
     ]
    }
   ],
   "source": [
    "corpus_of_subs = []\n",
    "for subreddits in subreddit:\n",
    "    corpus_of_subs.append(subreddits)\n",
    "\n",
    "\n",
    "voc2id = dict(zip(corpus_of_subs, range(len(corpus_of_subs))))\n",
    "rows, cols, vals = [], [], []\n",
    "for r, d in enumerate(document):\n",
    "    for e in d:\n",
    "        if voc2id.get(e) is not None:\n",
    "            rows.append(r)\n",
    "            cols.append(voc2id[e])\n",
    "            vals.append(1)\n",
    "user_subreddit_matrix = csc_matrix((vals, (rows, cols)), dtype=np.float32)\n",
    "print((user_subreddit_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSVD(user_subreddit_matrix, no_of_latent_factors):\n",
    "    \n",
    "    \"\"\"Compute the SVD of the given matrix.\n",
    "    :user_subreddit_matrix: a numeric matrix\n",
    "    :no_of_latent_factors : numeric scalar value\n",
    "    \n",
    "    :U  : User to concept matrix \n",
    "    :S  : Strength of the concepts matrix\n",
    "    :Vt : Subreddit to concept matrix\n",
    "    \"\"\"\n",
    "    U, s, Vt = sparsesvd(user_subreddit_matrix, no_of_latent_factors)\n",
    "    \n",
    "    dim = (len(s), len(s))\n",
    "    S = np.zeros(dim, dtype=np.float32)\n",
    "    for i in range(0, len(s)):\n",
    "        S[i,i] = mt.sqrt(s[i])\n",
    "\n",
    "    U = csc_matrix(np.transpose(U), dtype=np.float32)\n",
    "    S = csc_matrix(S, dtype=np.float32)\n",
    "    Vt = csc_matrix(Vt, dtype=np.float32)\n",
    "\n",
    "    return U, S, Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute estimated recommendations for the given user\n",
    "def computeEstimatedRecommendation(U, S, Vt, uTest):\n",
    "    \"\"\"Compute the recommendation for the given user.\n",
    "    \n",
    "    :U     : User to concept matrix \n",
    "    :S     : Strength of the concepts matrix\n",
    "    :Vt    : Subreddit to concept matrix\n",
    "    :uTest : Index of the user for which the recommendation has to be made\n",
    "    \n",
    "    :recom : List of recommendations made to the user\n",
    "    \"\"\"\n",
    " \n",
    "    #constants defining the dimensions of the estimated rating matrix\n",
    "    MAX_PID = len(subreddit)\n",
    "    MAX_UID = len(user)\n",
    "    \n",
    "    rightTerm = S*Vt \n",
    "\n",
    "    EstimatedRecommendation = np.zeros(shape=(MAX_UID, MAX_PID), dtype=np.float16)\n",
    "    for userTest in uTest:\n",
    "        prod = U[userTest, :]*rightTerm\n",
    "        # Converting the vector to dense format in order to get the indices \n",
    "        # of the movies with the best estimated ratings \n",
    "        \n",
    "        EstimatedRecommendation[userTest, :] = prod.todense()\n",
    "        recom = (-EstimatedRecommendation[userTest, :]).argsort()[:293]\n",
    "    return recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 293 subreddits contribute a total of 65.0 % to the total subreddits in the dataset\n"
     ]
    }
   ],
   "source": [
    "n_latent_fact = top_subreddit.subreddit[top_subreddit.cummulative_pct <= 65].count()\n",
    "contribution_pct = round(top_subreddit.cummulative_pct[len(subreddit[top_subreddit.cummulative_pct <= 65])-1],1)\n",
    "\n",
    "print(\"Top\", n_latent_fact ,\"subreddits contribute a total of\"\n",
    "      , contribution_pct,\"%\", \"to the total subreddits in the dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Demo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_latent_factors = top_subreddit.subreddit[top_subreddit.cummulative_pct <= 65].count() #293\n",
    "no_of_recommendations_for_each_user = 5\n",
    "uTest = [np.where(user == 'CarnationsPls')[0][0]]\n",
    "U, S, Vt = computeSVD(user_subreddit_matrix, no_of_latent_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Redditor: CarnationsPls\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "User Subreddit History - \n",
      "\n",
      "sports\n",
      "gaming\n",
      "gifs\n",
      "AskReddit\n",
      "fo4\n",
      "todayilearned\n",
      "TheLastAirbender\n",
      "realrule34\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Redditor: %s\\n\" % user[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"User Subreddit History - \\n\")\n",
    "\n",
    "##Getting users subs history where the vals in the matrix != 0\n",
    "previous_subredit_history = subreddit[np.where(user_subreddit_matrix[uTest[0],:].todense().T != 0)[0]]\n",
    "previous_subredit_history\n",
    "for previous_subredits in previous_subredit_history:\n",
    "     print(previous_subredits)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Recommendation for CarnationsPls : \n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Calgary\n",
      "Amd\n",
      "pcgaming\n",
      "techsupport\n",
      "NoMansSkyTheGame\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the top 5 subreddit recommendations for test user\n",
    "recommended_items = computeEstimatedRecommendation(U, S, Vt, uTest)\n",
    "final_recommendation = []\n",
    "for r in subreddit[recommended_items]:\n",
    "    ##Making sure the subreddits aren't from what they already viewed before (for Novelty)\n",
    "    if r not in previous_subredit_history:\n",
    "        final_recommendation.append(r)\n",
    "        if len(final_recommendation) == no_of_recommendations_for_each_user:\n",
    "            break\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Recommendation for %s : \\n\" % user[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "for recommendation in final_recommendation:\n",
    "    print(recommendation)\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation Demo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_latent_factors = top_subreddit.subreddit[top_subreddit.cummulative_pct <= 65].count() #293\n",
    "no_of_recommendations_for_each_user = 5\n",
    "uTest = [np.where(user == 'comicfan815')[0][0]]\n",
    "U, S, Vt = computeSVD(user_subreddit_matrix, no_of_latent_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Redditor: comicfan815\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "User Subreddit History - \n",
      "\n",
      "reactiongifs\n",
      "cringepics\n",
      "nba\n",
      "lakers\n",
      "NBA2k\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Redditor: %s\\n\" % user[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"User Subreddit History - \\n\")\n",
    "\n",
    "##Getting users subs history where the vals in the matrix != 0\n",
    "previous_subredit_history = subreddit[np.where(user_subreddit_matrix[uTest[0],:].todense().T != 0)[0]]\n",
    "previous_subredit_history\n",
    "for previous_subredits in previous_subredit_history:\n",
    "     print(previous_subredits)\n",
    "print(\"\\n------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------\n",
      "\n",
      "Recommendation for comicfan815 : \n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "\n",
      "rockets\n",
      "warriors\n",
      "bostonceltics\n",
      "sixers\n",
      "torontoraptors\n",
      "------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the top 5 subreddit recommendations for test user\n",
    "recommended_items = computeEstimatedRecommendation(U, S, Vt, uTest)\n",
    "final_recommendation = []\n",
    "for r in subreddit[recommended_items]:\n",
    "    ##Making sure the subreddits aren't from what they already viewed before (for Novelty)\n",
    "    if r not in previous_subredit_history:\n",
    "        final_recommendation.append(r)\n",
    "        if len(final_recommendation) == no_of_recommendations_for_each_user:\n",
    "            break\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "print(\"Recommendation for %s : \\n\" % user[uTest[0]])\n",
    "print(\"------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "for recommendation in final_recommendation:\n",
    "    print(recommendation)\n",
    "print(\"------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
